bayesian实例化

ML pipeline

Markov相关

召回率（查全率）、精确率（查准率）、准确率（全正确/所有）、F值（意义）

逻辑回归和线性回归对比有什么优点？

逻辑回归可以处理非线性问题吗？

分类问题有哪些评价指标？每种的适用场景。

讲一下正则化，L1和L2正则化各自的特点和适用场景。

讲一下常用的损失函数以及各自的适用场景。

讲一下决策树和随机森林

讲一下GBDT的细节，写出GBDT的目标函数。 GBDT和Adaboost的区别与联系

手推softmax loss公式

讲一下SVM, SVM与LR有什么联系。

讲一下PCA的步骤。PCA和SVD的区别和联系

讲一下ensemble

偏差和方差的区别。ensemble的方法中哪些是降低偏差，哪些是降低方差？ 

整数翻转，如何处理越界问题

C++多态，静态联编和动态联编，虚函数表

GMM原理，增大数据量是否会更好

模型融合如何做

股票买卖问题，一次买卖和两次买卖

提升树的思想，随机森林和提升树的区别

EM算法数学原理

SVM推导，对偶性的作用，核函数有哪些，有什么区别 

几种模型（ svm ， lr ， gbdt ， em ）的原理以及公式推导；

rf ， gbdt 的区别； gbdt ， xgboost 的区别（烂大街的问题最好从底层原理去分析回答）；

决策树处理连续值的方法；

4 ）特征选择的方法；

5 ）过拟合的解决方法；

6 ） kmeans 的原理，优缺点以及改进；

7 ）常见分类模型（ svm ，决策树，贝叶斯等）的优缺点，适用场景以及如何选型；

8 ） svm 为啥要引入拉格朗日的优化方法；

9 ）假设面试官什么都不懂，详细解释 CNN 的原理；

10 ）海量的 item 算文本相似度的优化方法；

11 ）梯度下降的优缺点；

12 ） em 与 kmeans 的关系；

13 ） L1 与 L2 的区别以及如何解决 L1 求导困难；

14 ）如何用尽可能少的样本训练模型同时又保证模型的性能；

15 ）解释 word2vec 的原理以及哈夫曼树的改进；

16 ）对推荐算法的未来看法；

17 ）在模型的训练迭代中，怎么评估效果；

18 ）有几个 G 的文本，每行记录了访问 ip 的 log ，如何快速统计 ip 出现次数最高的 10 个 ip ；如果只用 linux 指令又该怎么解决；

19 ）一个绳子烧完需要 1 个小时，假设所有绳子的材质都不一样，也不均匀，怎么取出 1 小时加 15 分钟；

20 ）假设有个 M*N 的方格，从最左下方开始往最右上方走，每次只能往右或者往上，问有多少种走法，假设中间有若干个格子不能走，又有多少种走法；

21 ）实现 hmm 的状态转移代码；

22 ）最短路径代码；

23 ）拼车软件是如何定价的以及如何优化；

24 ） 100 张牌，每次只能抽一张，抽过的牌会丢掉，怎么选出最大的牌；

25 ）怎么预测降雨量；

26 ） kmeans 代码；

27 ） mr 方案解决矩阵相乘的代码；

28 ） sql 语句的一些优化技巧；

29 ）关于集群调度的一些经验 trick 掌握多少；

30 ）设计一个系统可以实时统计任意 ip 在过去一个小时的访问量；

31 ）设计 LRU 系统；

